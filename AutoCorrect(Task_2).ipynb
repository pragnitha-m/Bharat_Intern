{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQTul-sNxeF2",
    "outputId": "14bf35fa-ba63-478a-b386-de447859a4a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from spellchecker import SpellChecker\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "import spacy\n",
    "#!python -m spacy download en_core_web_lg\n",
    "import en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0bUrfPgcy2qL"
   },
   "outputs": [],
   "source": [
    "nlp_model = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1ss-tnzyy8Co"
   },
   "outputs": [],
   "source": [
    "def find_nearest_word(word):\n",
    "    try:\n",
    "        target_vector = nlp_model.vocab[word].vector\n",
    "        target_vector_norm = target_vector.dot(target_vector) ** 0.5  # Calculate the norm of the target vector\n",
    "        similarities = [(w.text, target_vector.dot(w.vector) / (w.vector_norm * target_vector_norm))\n",
    "                        for w in nlp_model.vocab if w.has_vector]\n",
    "        nearest_word = max(similarities, key=lambda x: x[1], default=(word, 0))[0]  # Use the default value (original word) if no similar word is found\n",
    "        return nearest_word\n",
    "    except KeyError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "vJiN4PStzDfu"
   },
   "outputs": [],
   "source": [
    "def correct_words(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    spell = SpellChecker()\n",
    "\n",
    "    misspelled_tokens = [token for token in tokens if not spell.correction(token) == token]\n",
    "    corrected_sentence = [spell.correction(token) if token in misspelled_tokens else find_nearest_word(token) for token in tokens]\n",
    "\n",
    "    # Filter out any None values that might have resulted from find_nearest_word\n",
    "    corrected_sentence = [token for token in corrected_sentence if token is not None]\n",
    "\n",
    "    return \" \".join(corrected_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wINNABbuzbF7",
    "outputId": "7ae35d2d-3833-4f31-f5e9-052d561a6d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI >> Enter sentence or word to correct: i am embrassed\n",
      "Corrected >>  i am embarrassed\n"
     ]
    }
   ],
   "source": [
    "input_sentence = input(\"AI >> Enter sentence or word to correct: \")\n",
    "corrected_sentence = correct_words(input_sentence)\n",
    "print(\"Corrected >> \",corrected_sentence)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
